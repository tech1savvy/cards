---
id: 7.information-first
aliases: []
tags: []
---

# **Avoiding Hallucination** by ensuring **information collection precedes problem-solving** in custom GPT design.

- **Information Before Solution**: Always prioritize gathering information first; problem-solving should only happen once sufficient context is established.

---

**Hallucination Risk**: GPTs often generate convincing but inaccurate answers when they lack the necessary information.
**Sources of Information**:

- **Documents**: Policies, guides, and reference material.
- **User Context**: Critical details about the situation (e.g., medical need, emergency travel, specific conditions).
- **User Preferences**: Style of response (concise, verbose, quotation-based, etc.), learning style, or interaction model.
- **Past Interactions**: History within the conversation or previous external interactions (e.g., prior rulings by a financial unit manager).
- **Desired Outcome**: The format and purpose of the answer (summary, detailed explanation, recommendations).
  **Explicit Collection**: Prompt the user for missing details instead of making assumptions.
  **Confirmation Step**: Restate collected information and have the user confirm its accuracy before proceeding.
  **Instruction to GPT**: Explicitly guide the model not to jump to solutions prematurely, but to _ask questions, confirm details, then solve_.
  **Improved Accuracy and Usefulness**: Collecting context and preferences reduces hallucination, increases relevance, and results in answers the user finds both helpful and trustworthy.

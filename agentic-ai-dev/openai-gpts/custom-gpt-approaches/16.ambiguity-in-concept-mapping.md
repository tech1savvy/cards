---
id: 16.ambiguity-in-concept-mapping
aliases: []
tags: []
---

### **Concept Mapping Ambiguity**

> how to handle it in custom GPTs when user terminology doesn’t align clearly with the policy or knowledge base.

- **Concept Mapping Problem**: Users often use _terms or concepts that don’t exist in the policy_ (e.g., “Southwest Business Select”) or that could map to multiple policy categories.
- **Ambiguity Trigger**: If a user’s concept cannot be mapped unambiguously to policy terms, this _should trigger special handling_.

---

- **Avoid False Assumptions**: Without rules, the GPT may guess a mapping and generate incorrect or misleading answers.
- **Explicit Detection**: Custom GPTs should first analyze the user’s question to check whether all concepts can be mapped clearly to the knowledge base.
- **Unclear Answer State**: If mapping is ambiguous, the GPT should respond with “answer unclear” rather than giving a potentially wrong answer.
- **Offer Related Alternatives**: Instead of stopping completely, the GPT can provide policy-grounded questions the user _could_ ask (e.g., “Are airfare upgrades reimbursable?”).
- **User Guidance**: This approach helps the user rephrase their query using recognized policy terms, making the conversation more aligned with the knowledge base.
- **Safety Through Refusal**: By refusing to answer directly when mapping is ambiguous, the GPT reduces risk while still being helpful.
- **Transparency**: Clearly state why the answer is unclear (e.g., the term does not appear in the policy, or it could mean multiple things).
- **General Strategy**: Defining how the GPT should behave when concept mappings are unclear is a powerful safeguard against hallucination and misinterpretation.

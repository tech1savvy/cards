---
id: 11.boundries
aliases: []
tags: []
---

### **Defining and enforcing boundaries** in custom GPTs to prevent misuse, ambiguity, or unintended outcomes.

**Boundaries Are Essential**: Custom GPTs need _clear guardrails on what they will and will not do_ to avoid going “off the rails.”
**Unexpected User Behavior**: Users may submit prompts outside the intended scope (e.g., asking for images instead of test cases), so GPTs must handle edge cases gracefully.

---

**Explicit Prohibitions**: Define what the GPT must not generate (e.g., images, prompts for image generators, certain sensitive outputs).
**Guarantee Limitations**: GPTs should never promise guarantees (e.g., full compliance with financial regulations) that are impossible to prove—boundaries must reject such requests.
**Ambiguity Handling**: If a prompt is unclear (e.g., “make my test cases better”), the GPT should clarify the meaning instead of assuming.
**Response Conditions**: Only respond when the intent is clear enough; otherwise, prompt the user for clarification.
**Multiple Dimensions of Boundaries**: Boundaries may involve scope (what topics are allowed), guarantees (what can be promised), interpretation (clarity of user intent), and response scope (what outputs are permitted).
**Preventing Abuse**: Boundaries reduce potential misuse, such as crafting malicious text or manipulative prompts under disguised user requests.
**Risk Management**: Strong boundaries protect against harmful, inaccurate, or misleading outputs that could damage trust or compliance.
**Adaptation Mechanism**: The GPT must have defined fallback behaviors when a boundary is approached (e.g., decline, ask clarifying questions, or redirect).
